\documentclass[twocolumn]{article}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{hyperref}


\title{An example of using \LaTeX{} and Gnuplot: the Error Function}
\author{E. ~Amiri}

\begin{document}
\maketitle
\noindent
The error function, often denoted by $\textrm{erf}$, is defined as: 
\begin{eqnarray}\label{err-eq}
\textrm{erf} x &=& \frac{1}{\sqrt{\pi}} \int_{-x}^{x}e^{-t^{2}} dt,\;
\\
&=& \frac{2}{\sqrt{\pi}} \int_{0}^{x}e^{-t^{2}} dt\;.
\end{eqnarray}

This integral is a special (non-elementary) and sigmoid function that occurs often in probability, statistics, and partial differential equations.

In statistics, for non-negative values of $x$, the error function has the following interpretation: 

For a random variable $Y$ that is normally distributed with mean $0$ and variance $1/2$, $\textrm{erf} x$ is the probability that $Y$ falls in the range $\left[-x,x\right]$.

\begin{figure}[h!]
\input{plot-exp.tex}
\caption{A graph of the error function between -3 and 3.}
\end{figure}

\subsection*{Name}
The name "error function" and its abbreviation erf were proposed by J. W. L. Glaisher in 1871 on account of its connection with "the theory of Probability, and notably the theory of Errors". The error function complement was also discussed by Glaisher in a separate publication in the same year. For the "law of facility" of errors whose density is given by

\begin{equation}\label{density}
f(x)= \left(\frac{c}{\pi}\right)^{1/2} e^{-cx^{2}}
\end{equation}
(the normal distribution), Glaisher calculates the chance of an error lying between $p$ and $q$ as: 
\begin{equation}\label{err-ex}
\left(\frac{c}{\pi}\right)^{1/2} \int_{p}^{q} e^{-cx^{2}} dx = \frac{1}{2} \left(\textrm{erf}(q\sqrt{c}) - \textrm{erf}(p\sqrt{c}) \right).
\end{equation}

\subsection*{Applications}
When the results of a series of measurements are described by a normal distribution with standard eviation $\sigma$ and expected value $0$, then $\textrm{erf}\left(\frac{a}{a\sqrt{2}} \right)$ is the probability that the error of a single measurement lies between $-a$ and $+a$ for positive $a$. This is useful, for example, in determining the bit error rate of a digital communication system.

The error function and its approximations can be used to estimate results that hold with high probability of with low probability. Given random variable $X ~ \textrm{Norm} [\mu,\sigma]$ and constant $L<\mu$:
\begin{equation}
\textrm{Pr}[X\leq L]=\frac{1}{2}+\frac{1}{2} \textrm{erf}\left(\frac{L-\mu}{\sqrt{2}\sigma}\right) \approx A \exp(-B\left(\frac{L-\mu}{\sigma}\right)^{2})
\end{equation}
where $A$ and $B$ are certain numeric constants. If $L$ is sufficiently far from the mean, i.e $\mu-L \geq \sigma \sqrt{\ln{k}}$, then: 
\begin{equation}
\textrm{PR}[X \leq L] \leq A \exp(-B \ln{k}) = \frac{A}{k^{B}}
\end{equation}
so the probability goes to $0$ as $k \rightarrow \infty$.

\subsection*{References}
Wikipedia, Error Function: \url{https://en.wikipedia.org/wiki/Error_function}.

\end{document}
